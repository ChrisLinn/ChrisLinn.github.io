#+HTML_HEAD: <link rel="stylesheet" href="../asset/css/page.css" type="text/css" media="screen" />
#+title: function compose, type cut, and the algebra of logic is a natural field

------

@@html:
<p> this article is not finished yet </p>
@@

------

------

@@html:
<p> Mathematics is common sense. -- Errett Bishop </p>
@@

------

* first I would like to summarize intuitionistic logic

  - first I would like to summarize intuitionistic logic
    it is also called constructive logic
    it is very well known now
    and is gloriously called the Brouwer–Heyting–Kolmogorov interpretation

  - to prove (P and Q)
    is to prove P and prove Q
    - this is the same as classical logic

  - to prove (P or Q)
    is to prove P or prove Q
    - while in classical logic
      you can prove (P or Q)
      without a proof of P
      and without a proof of Q

  - to prove (P -> Q)
    is to prove that
    if we have a proof of P
    then we can construct a proof of Q
    - this is the same as classical logic

  - to prove (not P)
    is to prove (P -> something-we-consider-wrong)
    - something-we-consider-wrong like (0 = 1)
    - (not (not P)) is weaker than P
      while in classical logic
      (not (not P)) is equal to P

  - to prove "for all x belong to A, we have P(x)"
    is to prove that
    for all x belong to A
    we can construct a proof of P(x)
    - this is the same as classical logic

  - to prove "there exist x belong to A, such that P(x)"
    is to construct a value of type A
    and construct a proof of P(x)
    - the only way to prove something exist
      is to find such thing
    - while in classical logic
      to prove something exist
      you do not need to find such thing

* let us design a formal language to express theorem

  - let us design a formal language to express theorem

  - firstly we see the fact that the general form of theorem is like (A -> B)
    let us unite our syntax toward "->"
    we do not write A
    instead we will write (-> A)
    - this is just like one does not write 3 but write 1\3 or 3/1 instead

  - and let us optimize our syntax for "and"
    we do not write ((A and B) -> (C and D))
    but just write (A B -> C D)

  - I call express of form (A B C ... -> E F G ...) sequent or arrow
    this term is taken from Gentzen
    but you should note that
    sequent for us is not exactly the same as sequent for Gentzen
    for Gentzen (A B -> C D) is viewed as ((A and B) -> (C or D))
    but for us (A B -> C D) is viewed as ((A and B) -> (C and D))
    - if you want to know more about the meaning of sequent for Gentzen
      please see his paper "investigations into logical deduction"

  - how about (C or D) ? you might ask
    I would say, let us ignore (C or D) for now
    we will not be able to express such thing in our language
    but no worry
    because we will be able to express
    "there exist x belong to A, such that P(x)" in our language
    you see that (C or D) is an unnamed way to express alternative
    while "there exist x belong to A" is a named way to express alternative
    so, whenever we want to express alternative
    we would have to introduce name
    - we can add "or" back to our language later
      but I insist that we ignore "or" for now
      because I want the language to be simple

  - I also suggest to ignore "not"
    because you see that (not P) is just (P -> something-we-consider-wrong)
    the negation we want to express
    is parameterized by something-we-consider-wrong
    (or say, depends on something-we-consider-wrong)
    if we simple say (not P)
    the information of this parameterization will be lost

  - I express "for all x belong to A, we have P(x)"
    as ((x : A) -> x P)
    and express "there exist x belong to A, such that P(x)"
    as (-> (x : A) x P)
    I am using postfix notation here
    I write "x P" instead of "P(x)"
    - why should we use postfix notation ? one wonders
      you might argue that
      compare to the traditional math notation, it looks really alien
      if you care, please see [[rationale of using postfix notation]]

  - recall that
    ((x : A) -> x P) means "for all x belong to A, we have P(x)"
    (-> (x : A) x P) means "there exist x belong to A, such that P(x)"
    in the above two example expressions
    variables are written in lower-case latin letter
    functions are written in upper-case latin letter
    personally I do not wish to
    distinguish meaning by lower-case v.s. upper-case
    (maybe because I am a scheme user, or maybe because I am a Chinese)
    so, in the following implementation of our language
    I will write
    #+begin_src scheme
    ((:x : a) -> :x p)
    (-> (:x : a) :x p)
    #+end_src

  - now that we have designed a language to express theorem
    where except for the symbol "->" setting in the
    and every thing else seems are intrinsic to the language
    let us write some examples

  - ><><><

    #+begin_src scheme
    (* wanderer/poe (-> poe is-wanderer))
    (* way-worn (:x is-wanderer -> :x is-weary))
    (~ weary/poe (-> poe is-weary)
       (-> wanderer/poe way-worn))


    (+ natural (-> type)
       zero (-> natural)
       succ (natural -> natural))

    (~ natural-induction

       ((:p : (natural -> type))
        zero :p apply
        ((:k : natural) :k :p apply -> :k succ :p apply)
        (:x : natural) -> :x :p apply)

       (:p :p/z :p/s zero -> :p/z)
       (:p :p/z :p/s :k succ ->
           :k
           :p :p/z :p/s :k natural-induction
           :p/s apply))
    #+end_src

* >< theorem can be viewed as type of function

  - theorem can be viewed as type of function
    this is well known as "theorem as type"

  - ><><><

  - natural number
    #+begin_src scheme
    (+ natural (-> type)
       zero (-> natural)
       succ (natural -> natural))

    (~ add (natural natural -> natural)
       (:m zero -> :m)
       (:m :n succ -> :m :n add succ))

    (~ mul (natural natural -> natural)
       (:m zero -> zero)
       (:m :n succ -> :m :n mul :m add))

    (~ factorial (natural -> natural)
       (zero -> zero succ)
       (:n succ -> :n factorial :n succ mul))
    #+end_src

  - stack processing
    #+begin_src scheme
    (~ drop (:t ->)
       (:d ->))

    (~ dup (:t -> :t :t)
       (:d -> :d :d))

    (~ over (:t1 :t2 -> :t1 :t2 :t1)
       (:d1 :d2 -> :d1 :d2 :d1))

    (~ tuck (:t1 :t2 -> :t2 :t1 :t2)
       (:d1 :d2 -> :d2 :d1 :d2))

    (~ swap (:t1 :t2 -> :t2 :t1)
       (:d1 :d2 -> :d2 :d1))
    #+end_src

  - list
    #+begin_src scheme
    (+ list ({:t : type} :t -> type)
       null (-> :t list)
       cons (:t list :t -> :t list))

    (~ append (:t list :t list -> :t list)
       (:l null -> :l)
       (:l :r :e cons -> :l :r append :e cons))

    (~ map (:t1 list (:t1 -> :t2) -> :t2 list)
       (null :f -> null)
       (:l :e cons :f -> :l :f map :e :f apply cons))
    #+end_src

  - vector
    #+begin_src scheme
    (+ vector ({:t : type} natural :t -> type)
       null (-> zero :t vector)
       cons (:n :t vector :t -> :n succ :t vector))

    (~ append (:m :t vector :n :t vector -> :m :n add :t vector)
       (:l null -> :l)
       (:l :r :e cons -> :l :r append :e cons))

    (~ map (:n :t1 vector (:t1 -> :t2) -> :n :t2 vector)
       (null :f -> null)
       (:l :e cons :f -> :l :f map :e :f apply cons))
    #+end_src

* >< the way we write functions forms a language to record deduction

  - the way we write functions forms a language to record deduction
    a record of many steps of deduction is called a proof
    this is well known as "function as proof"

    | deduction   | language to record deduction |
    |-------------+------------------------------|
    | cut         | function composition         |
    | exist-intro | define new type              |
    | exist-elim  | branching by a list of arrow |
    | conj-elim   | binding by unification       |

  - first is cut
    it is the hero deduction rule
    which occupys the center of the stage of Gentzen's sequent calculus
    it says if we have (A -> B) and (B -> C)
    cut them together, we get (A -> C)

  - on the other hand
    if we have function f1 of type (A -> B) and f2 of (B -> C)
    compose f1 and f2, we get a function of type (A -> C)
    this is what I mean by "function compose, type cut" in the title

  - ><><><

* >< carefully define equality of theorem, we will get a natural field

  - carefully define equality of theorem, we will get a natural field

    | deduction   | language to record deduction | logic field     |
    |-------------+------------------------------+-----------------|
    | cut         | function composition         | weaken          |
    | exist-intro | define new type              | field extension |
    | exist-elim  | branching by a list of arrow | distributive    |
    | conj-elim   | binding by unification       |                 |

  - ><><><

*** the natural field

    - let us view theorem (A -> B) as fraction
      A as denominator
      B as numerator
      - so, one might write (A \ B)
        note that
        we are using reverse-slash instead of slash
        to maintain the order of A B in (A -> B)

    - to add two theorems (A -> B) and (C -> D)
      we get (A B -> (B C or A D))
      - just like (A \ B) + (C \ D) = (A C \ (B C + A D))

    - theorems under addition is an Abelian semigroup
      we do not have identity element
      and we do not have inverse
      - of course, we can introduce a "zero-theorem"
        (a theorem that we can never prove)
        as the identity element of addition
        to make our algebraic structure more like fraction of natural number
        but let us do not do this for now

    - to multiply two theorems (A -> B) and (C -> D)
      we get (A C -> B D)
      - just like (A \ B) (C \ D) = (A C \ B D)

    - theorems under multiplication is an Abelian group
      identity element is (->)
      inverse of (A -> B) is (B -> A)

    - distributive is just like fraction of natural number
      because the way we define addition
      is just like the addition of fraction of natural number

    - I would like to coin a new term "natural field"
      for our algebraic structure
      to recall its similarites between the fraction of natural number
      - note that
        other terms like 'semi-field' is ambiguous
        because it does not inform us
        whether addition or multiplication is semi

*** the order structure of our natural field

    - the next question one should ask is
      what is the relation between this natural field and deduction ?
      the answer relates to the order structure of our natural field
      (actually we have a lattice, I will address its detail in another article)

    - just like natural number
      we have an order between elements of natural field
      I will use the term "weaker" to denote this order relation
      for natural number, we say, x is less than y
      for natural field, let us say, x is weaker than y
      - but our definition will not be total
        thus we will only have a poset (partially ordered set)

    - let us define "weaker" as
      - (-> (A or B)) is weaker than (-> A)
        (-> (A or B)) is weaker than (-> A)
      - (-> :x :x) is weaker than (-> :x :y)
        (-> :x P :x P) is weaker than (-> :x P :y P)
      - if X is weaker than Y
        then the reverse of Y is weaker than X

*** the relation between natural field of logic and deduction

    - now we can observe that
      deduction is
      to build new theorem by addition or multiplication theorems
      or weaken a theorem

    - cut can be viewed as an important way to weaken a theorem
      recall that
      if we have (A -> B) and (B -> C)
      cut them, we get (A -> C)
      multiply them, we get (A B -> B C)
      we can view cut as changing (A B -> B C) to (A -> C)
      - just like the fraction of natural number
        where (A B \ B C) = (A \ C)

    - I said that, cut can be viewed as weaken
      but the above example is not weakening the theorem at all
      while the following example do
      if we have theorem (A -> B) and ((B or D) -> C)
      cut them, we can deduce theorem (A -> C)
      - just like for the fraction of natural number
        we have (A B \ (D + B) C) > (A \ C)

*** to summarize

    - the algebraic structure of logic is a natural field
    - deduction is
      to build new theorem by addition and multiplication theorems
      or weaken a theorem
    - cut can be viewed as an important way to weaken a theorem
    - a proof is a record of many steps of deductions

* >< an attempt to implement such a language

  - ><><><

  - project page : http://xieyuheng.github.io/sequent1

* appendix

*** >< remark on formal language for deduction and proof

    - ><><><
      A proof is any completely convincing argument. -- Errett Bishop

*** rationale of using postfix notation

    - rationale of using postfix notation is the following
      in the linear writing system of our language
      we can roughly distinguish four kinds of notations for function or predicate
      | infix     | ((1 + 2) + 3) |
      | prefix    | + + 1 2 3     |
      | postfix   | 3 2 1 + +     |
      | borderfix | (+ 1 2 3)     |
      - infix is especially good for associative binary function
      - prefix and postfix are not ambiguous without bracket
      - borderfix can be used for functions
        that can apply to different numbers of arguments
      our choice is between prefix and postfix
      because for simplicity we have the following two features
      - the arity of all functions must be fixed
      - we want our expressions to be not ambiguous without bracket
      then, how do we decide to use postfix instead of prefix ?
      seemingly, prefix and postfix are symmetric
      while we still can distinguish them
      because we write in special order (from left to right in most western language)
      in postfix notation suppose we have written
      1 2 +
      and we want to add 3 to the result of 1 2 +
      we simply write
      1 2 + 3 +
      while in prefix notation suppose we have written
      @@html: + 1 2 @@
      and we want to add 3 to the result of + 1 2
      we have to insert + 3 in front of + 1 2 and write
      @@html: + 3 + 1 2 @@
      I summarize this difference by say
      postfix notation respect the special order of a linear writing system
      the above conclude my rationale

*** >< rationale of function composition over function application

    - ><><><
      function composition
      associative
      rich

    - ><><><
      Hilbert system
      combinatory logic
      function application

*** remark on deduction and inference

    - first question one might ask is
      what is a deduction or a inference ?
      my answer is a deduction or a inference
      is a way to express a change of theorem
      "a change" means "one step of change"

    - let us generalized a little bit
      and to discuss "a change of thing" and "language to record changes"
      you will find these two concepts are very common
      and they also are named gloriously in different places
      | thing   | a change of thing     | language to record changes |
      |---------+-----------------------+----------------------------|
      | theorem | deduction             | proof                      |
      | food    |                       | cookbook                   |
      | data    |                       | algorithm                  |
      | number  | elementary arithmetic |                            |
      (seems to me a market for language designer)

*** remark on conj-intro and conj-elim

    - the following seems like conj-intro and conj-elim in natural deduction
      but we can use stack processing function to express them
      #+begin_src scheme
      ;; conj-intro
      (* p1 (-> a))
      (* p2 (-> b))
      (~ p3 (-> a b)
         (-> p1 p2))

      (* drop (:t ->)
         (:d ->))
      (~ swap (:t1 :t2 -> :t2 :t1)
         (:d1 :d2 -> :d2 :d1))

      ;; conj-elim
      (* p3 (-> a b))
      (~ p1 (-> a)
         (-> p3 drop))
      (~ p1 (-> a)
         (-> p3 swap drop))
      #+end_src
