#+HTML_HEAD: <link rel="stylesheet" href="../asset/css/page.css" type="text/css" media="screen" />
#+title: function compose, type cut, and the algebra of logic

------
@@html:
<p> auther : XIE Yuheng, a math student of China </p>
<p> date: 2016/06/14 (this paper is still under revising) </p>
<p> keywords :  language design, dependent type, deduction system, sequent calculus </p>
@@
------

* abstract

  - some said,
    [for example, see the wikipedia page of "Curry–Howard correspondence", at the time when this paper is written]
    in the framework of Curry–Howard correspondence,
    Gentzen's sequent calculus does not correspond with
    a well-defined pre-existing model of computation,
    as it was for Hilbert-style and natural deduction.

    - in this paper, I will show that
      we can get what sequent calculus corresponds to,
      not by designing a new model of computation,
      but by changing the syntax of well known model.

    - I will show that
      sequent calculus corresponds to a functional programming language,
      the syntax of which is optimized for function composition
      instead of function application.

    - I will also show the trade-off of this syntax design.
      how we lose the implicit syntax for currying.
      how we gain the algebraic associative law.
      and how one's view of deduction can be changed by the change of syntax.

  - some also said, [for example, see the first chapter of "Homotopy Type Theory"]
    deduction system can be viewed as algebraic structure,
    where theorems are the elements (like elements of group),
    where deductive rules are the operations (like multiplication of group).

    - in this paper, I will show that
      with the associative law which we obtained from function composition,
      the corresponding deduction system of our programming language
      is a very rich algebraic structure.

    - I will define the rich-ness & poor-ness of algebraic structure,
      and provide my arguments in the framework I defined.

  - in this paper, I will also introduce a prototype implementation of such a language.
    I call it "sequent1".

* background

*** how the idea was conceived

    - two years ago,
      for some reason, I learned the design of the stack-based language -- forth.
      I began to write my own forth-like language,
      and tried to add various features to it.
      soon I found another forth-like language -- joy.
      from joy I learned the composition v.s. application trade-off in syntax.

    - I added more and more features to my forth-like language.
      things went well, until I tried to add a type system to the it.
      I found that
      to design a good type system,
      a designer has to know Curry–Howard correspondence well.

    - and after some learning,
      I figured that
      the composition v.s. application trade-off in syntax,
      corresponds to
      the sequent-calculus v.s. natural-deduction in proof theory.

    - I tried to add such a sequent-calculus type system
      to the forth-like language several times.
      I failed.
      because the implementation is written in assembly language,
      the low-level detailed code would soon exceed the complexity
      that a normal people like me can manage.

    - I steped back.
      I decided to write a prototype language in scheme.
      the prototype only limited to demonstrates the main idea of "sequent-calculus as type system".
      thus I wrote "sequent1".

*** >< related works

    - I declared that the computational models ><
      but I changed the ><><><

    - while
      linear logic and ><><>< computational models

    - maybe one logic system can corresponds to multiple computational models

* the change of syntax

  - I will introduce my syntax by comparing it with
    the syntax of an imaginary agda-like (or idris-like) language.
    I will mark its syntax by << application-language >>,
    and I will mark my syntax by << composition-language >>.

*** natural number

    - << application-language >>
      #+begin_src idris
      data natural : type where
        zero : natural
        succ : natural -> natural

      add : natural -> natural -> natural
      add zero n = n
      add (succ m) n = succ (add m n)

      mul : natural -> natural -> natural
      mul zero n = zero
      mul (succ m) n = add n (mul m n)
      #+end_src

    - note that,
      in the following examples
      "~" can be readed as "define-function",
      "+" can be readed as "define-type".

    - << composition-language >>
      #+begin_src scheme
      (+ natural (-> type)
         zero (-> natural)
         succ (natural -> natural))

      (~ add (natural natural -> natural)
         (:m zero -> :m)
         (:m :n succ -> :m :n add succ))

      (~ mul (natural natural -> natural)
         (:m zero -> zero)
         (:m :n succ -> :m :n mul :m add))
      #+end_src

*** detailed explanation of above example

    - explanation
      #+begin_src scheme
      (note
        the second arrow of the function body of
        (~ mul (natural natural -> natural)
           (:m zero -> zero)
           (:m :n succ -> :m :n mul :m add))
        which is
        (:m :n succ -> :m :n mul :m add)
        (note
          the antecedent of (:m :n succ -> :m :n mul :m add)
          is (:m :n succ)
          it can be viewed as 3 functions composed together
          the type of each of them are showed by the following list
          ((:m (-> natural))
           (:n (-> natural))
           (succ (natural -> natural)))
          the resulting type is
          (-> natural natural))
        (note
          the succedent of (:m :n succ -> :m :n mul :m add)
          is (:m :n mul :m add)
          it can be viewed as 4 functions composed together
          the type of each of them are showed by the following list
          ((:m (-> natural))
           (:n (-> natural))
           (mul (natural natural -> natural))
           (:m (-> natural))
           (add (natural natural -> natural)))
          the resulting type is
          (-> natural)))
      #+end_src

*** currying must also be explicit

    - in type, input arguments and return values are made explicit.
      instead of (natural -> natural -> natural),
      we write (natural natural -> natural).

    - thus, in function body, currying must also be explicit.
      we lost the implicit syntax for currying.

*** vector

    - << application-language >>
      #+begin_src idris
      data vector : natural -> type -> type where
        null : vector zero t
        cons : t -> vector n t -> vector (succ n) t

      append : vector m t -> vector n t -> vector (add m n) t
      append null       l = l
      append (cons e r) l = cons e (append r l)

      map : (m : a -> b) -> f a -> f b
      map f null       = null
      map f (cons e l) = cons (f e) (map f l)
      #+end_src

    - << composition-language >>
      #+begin_src scheme
      (+ vector (natural type -> type)
         null (-> zero :t vector)
         cons (:n :t vector :t -> :n succ :t vector))

      (~ append (:m :t vector :n :t vector -> :m :n add :t vector)
         (:l null -> :l)
         (:l :r :e cons -> :l :r append :e cons))

      (~ map (:n :t1 vector (:t1 -> :t2) -> :n :t2 vector)
         (null :f -> null)
         (:l :e cons :f -> :l :f map :e :f apply cons))
      #+end_src

*** unified syntax

    - the syntax of type and function-body seem to be the same.

    - it is true,
      and it is also semanticly true.
      because, in the implementation,
      we have "apply", which uses function-body (a list of arrow) to do computation,
      we also have "type-apply", which uses type (a type-arrow) to do computation.
      (the "type-apply" is used during type-check)
      and the way how these computations are done is also unified.

*** different optimization of syntax

    - ><><><

***** for function composition

      - << application-language >>
        #+begin_src idris
        compose : {A B C : type} (A -> B) -> (B -> C) -> (A -> C)
        compose f g = λ x -> (f (g x))
        #+end_src

      - << composition-language >>
        the syntax is optimized for function composition.
        function composition is expressed by term concatenation.

***** for function application

      - << application-language >>
        the syntax is optimized for function application.
        function application is expressed by term concatenation.

      - << composition-language >>
        #+begin_src scheme
        (~ apply (:a :b ... (:a :b ... -> :c :d ...) -> :c :d ...)
           (note it is implemented as a primitive-function))
        #+end_src

*** stack processing

    - multiple return values are easily handled,
      and stack-processing functions can be used to help to
      re-order return values (without naming them) for function composition.
      (just like in forth & joy)

    - << composition-language >>
      #+begin_src scheme
      (~ drop (:t ->)
         (:d ->))

      (~ dup (:t -> :t :t)
         (:d -> :d :d))

      (~ over (:t1 :t2 -> :t1 :t2 :t1)
         (:d1 :d2 -> :d1 :d2 :d1))

      (~ tuck (:t1 :t2 -> :t2 :t1 :t2)
         (:d1 :d2 -> :d2 :d1 :d2))

      (~ swap (:t1 :t2 -> :t2 :t1)
         (:d1 :d2 -> :d2 :d1))
      #+end_src

* Curry–Howard correspondence under this syntax

  - to show such correspondence
    is to show,
    1. how to view type as theorem ?
    2. how to view function as proof ?

*** type as theorem

    - with the ability to handle multiple return values,
      we can express "and" easily.
      #+begin_src scheme
      (A B -> C D) -- "(A and B) implies (C and D)"
      #+end_src
      we can express "for all" and "there exist" in an unified way.
      #+begin_src scheme
      ((:x : A) -> :x P) -- "for all x belong to A, we have P(x)"
      (-> (:x : A) :x P) -- "there exist x belong to A, such that P(x)"
      #+end_src

    - I call express of form (A B C ... -> E F G ...) sequent.
      but you should note that,
      sequent for us, is not exactly the same as sequent for Gentzen.
      Gentzen views succedent as "or", while we view succedent as "and".
      #+begin_src scheme
      for Gentzen -- (A B -> C D) -- "(A and B) implies (C or D)",
      for us      -- (A B -> C D) -- "(A and B) implies (C and D)".
      #+end_src

*** function as proof

    - "function as proof" means,
      the way we write function body forms a language to record deduction.
      a record of many steps of deduction is called a proof.

    - let us summarize deductive rules in sequent calculus in our language
      I will simplify some explicit contexts variables from them
      because for our language contexts can be implicit

***** cut

      - cut
        #+begin_src scheme
        f : (A -> B)
        g : (B -> C)
        --------------
        f g : (A -> C)
        #+end_src

***** structural

      - left-weakening
        #+begin_src scheme
        f : (A -> C)
        -------------------
        drop f : (A B -> C)
        #+end_src

      - left-contraction
        #+begin_src scheme
        f : (A A -> B)
        ----------------
        dup f : (A -> B)
        #+end_src

      - right-contraction
        #+begin_src scheme
        f : (A -> B B)
        -----------------
        f drop : (A -> B)
        #+end_src

      - left-permutation
        #+begin_src scheme
        f : (A B -> C)
        -------------------
        swap f : (B A -> C)
        #+end_src

      - right-permutation
        #+begin_src scheme
        f : (A -> B C)
        -------------------
        f swap : (A -> C B)
        #+end_src

***** and

      - left-and-1
        #+begin_src scheme
        f : (A -> C)
        -------------------
        drop f : (A B -> C)
        #+end_src

      - left-and-2
        #+begin_src scheme
        f : (B -> C)
        ------------------------
        swap drop f : (A B -> C)
        #+end_src

      - right-and
        #+begin_src scheme
        f : (A -> B)
        g : (C -> D)
        ----------------------------
        g swap f swap : (A C -> B D)
        #+end_src

***** or

      - right-or-1
        #+begin_src scheme
        f : (A -> B)
        -------------------
        f : (A -> (B or C))
        #+end_src

      - right-or-2
        #+begin_src scheme
        f : (A -> C)
        -------------------
        f : (A -> (B or C))
        #+end_src

      - left-or
        #+begin_src scheme
        f : (A -> B)
        g : (C -> D)
        -----------------------------
        (case (:x {:x : A} -> :x f)
              (:y {:y : C} -> :y g))
        : ((A or C) -> (B or D))
        #+end_src

***** implies

      - left-implies
        #+begin_src scheme
        f : (A -> B)
        g : (C -> D)
        --------------------------
        (:a :h -> :a f :h apply g)
        : (A (B -> C) -> D)
        #+end_src

      - right-implies
        #+begin_src scheme
        f : (A B -> C)
        -----------------------
        (:x -> (:y -> :x :y f))
        : (A -> (B -> C))
        #+end_src

* >< algebra of logic

  - since function composition satisfy associative law
    I think I can design (or seek for) an algebraic structure
    for formal theorems

  - we will only define those algebraic operations
    that are closed in the set of derivable theorems

  - hopefully we will be able to capture all deduction by algebraic operations

  - [[remark on algebraic structure]]

*** to mimic fraction of natural number

    - let us view theorem (A -> B) as fraction,
      A as denominator,
      B as numerator.
      - just like (A \ B).
        note that,
        we are using reverse-slash instead of slash,
        to maintain the order of A B in (A -> B).

*** multiplication

    - to multiply two theorems (A -> B) and (C -> D),
      we get (A C -> B D).
      - just like (A \ B) (C \ D) = (A C \ B D).

      #+begin_src scheme
      (* r (A -> B))
      (* s (C -> D))

      (~ r/s/mul (A C -> B D)
         (:x :y -> :x r :y s))

      ;; abstract it to a combinator
      (~ general/mul ((:a -> :b) (:c -> :d) -> (:a :c -> :b :d))
         (:r :s -> (lambda (:a :c -> :b :d)
                     (:x :y -> :x :r apply :y :s apply))))
      #+end_src

    - theorems under multiplication is an Abelian group.
      identity element is (->).
      inverse of (A -> B) is (B -> A).

*** two definitions of addition

***** first definition

      - this definition recalls the fraction of natural number
        but it seems not natural when written as function in our language

      - to add two theorems (A -> B) and (C -> D)
        we get (A B -> (B C or A D))
        - just like (A \ B) + (C \ D) = (A C \ (B C + A D))

        #+begin_src scheme
        (* r (A -> B))
        (* s (C -> D))

        (~ r/s/fraction-add (A C -> (B C or A D))
           (:x :y -> :x r :y)
           (:x :y -> :x :y s))

        ;; abstract it to a combinator
        (~ general/fraction-add ((:a -> :b) (:c -> :d) -> (:a :c -> (:b :c or :a :d)))
           (:r :s -> (lambda (:a :c -> (:b :c or :a :d))
                       (:x :y -> :x :r apply :y)
                       (:x :y -> :x :y :s apply))))
        #+end_src

      - distributive is just like fraction of natural number
        because the way we define addition
        is just like the addition of fraction of natural number

      - theorems under addition is an Abelian semigroup
        we do not have identity element
        and we do not have inverse
        - of course, we can introduce a "zero-theorem"
          (a theorem that we can never prove)
          as the identity element of addition
          to make our algebraic structure more like fraction of natural number
          but let us do not do this for now

      - under this definition of addition
        one may call the algebraic structure "natural field"
        to recall its similarites between the fraction of natural number
        - note that
          other terms like 'semi-field' is ambiguous
          because it does not inform us
          whether addition or multiplication is semi

***** second definition

      - this definition seems natural in our language

      - to add two theorems (A -> B) and (C -> D)
        we get ((A or B) -> (C or D))

        #+begin_src scheme
        (* r (A -> B))
        (* s (C -> D))

        (~ r/s/mul-like-add ((A or C) -> (B or D))
           (:x -> :x r)
           (:y -> :y s))

        ;; abstract it to a combinator
        (~ general/mul-like-add ((:a -> :b) (:c -> :d) -> ((:a or :c) -> (:b or :d)))
           (:r :s -> (lambda ((:a or :c) -> (:b or :d))
                       (:x -> :x :r apply)
                       (:y -> :y :s apply))))
        #+end_src

      - distributive also hold under this definition of addition
        because (-> A (B or C)) is the same as (-> (A B or A C))

      - theorems under addition is an Abelian semigroup
        identity element is (->)
        but we do not have inverse

*** term-lattice, and cut as weaken

    - this is where we must take term-lattice into account.

      | lattice          | term                   |
      |------------------+------------------------|
      | meet             | unification (uni)      |
      | join             | anti-unification (ani) |
      | greater-or-equal | cover (or match)       |

      - note that,
        "equal" can be defined by "greater-or-equal".

    - term-lattice is also called "subsumption lattice" by other authers
      I call it "term-lattice"
      because I want to make explicit its relation with term-rewriting-system
      (I will address the detail of term-lattice in another paper)

    - if we have (A -> B) and (C -> D)
      we can cut them only when (C cover B)
      for example when
      - C = B
      - C = (B or E)
      - C = :x :y P
        B = :x :x P

    - cut can be viewed as an important way to weaken a theorem
      because we can first
      multiply (A -> B) and (C -> D)
      to (A C -> B D)
      then weaken it to (A -> D)
      - provides that (C cover B)

    - we can extend the term-lattice to cedent (antecedent and succedent)
      because cedent is Cartesian product of term in the term-lattice

*** type-check, again

    - with the new terminology introduced by term-lattice
      we can express type-check in a better way

    - type-arrow : (A -> B)
      arrows in function body : (a1 -> b1) (a2 -> b2)
      (A uni a1) ((rewrite b1) cover (rewrite B))
      (A uni a2) ((rewrite b1) cover (rewrite B))
      - note that
        after (A uni a1)
        ((rewrite b1) cover (rewrite B)) is performed with new bindings

*** >< definition as extension of algebraic structure

    - ><

    - extend freely by "*"

    - extend by "+"

    - difference between "+" and "*"

* >< implementation

  - I made an attempt to implement a prototype of the language
    (project page at http://xieyuheng.github.io/sequent1)

*** >< the prototype language

    - during writing the prototype language
      I noticed the language is not necessarily stack-based
      and we have the following correspondence
      | implementation tech     | the natural of language       |
      |-------------------------+-------------------------------|
      | stack-based computation | call-by-value (non-lazy-eval) |
      | term-rewriting-system   | call-by-name (lazy-eval)      |
      | graph-rewriting-system  | call-by-need (lazy-eval)      |

*** >< limits of my implementation

* >< conclusion

  - >< about better language

* >< further work

  - I planed to do ><><><
  - the meaning of equality
  - dependent type system for logic programming language

* appendixes

*** remark on formalization

    - I agree with Errett Bishop who said
      "a proof is any completely convincing argument."
      I also think theorems expressed by formal language are specially clear
      and proofs checked by computer are specially convincing

    - on the other hand
      I also think that
      formal language can never be used to satisfactorily explain
      or totally simulate human language
      formal theorem and formal proof can never fully capture "human proof"
      this fact is specially clear
      if you are willing to think of "human proof" historically

    - the aim (or one aim) of formalization is to reduce (or remove) vagueness
      while the definition of vagueness is always vague

*** rationale of using postfix notation

    - rationale of using postfix notation is the following
      in the linear writing system of our language
      we can roughly distinguish four kinds of notations for function or predicate
      | infix     | ((1 + 2) + 3) |
      | prefix    | + + 1 2 3     |
      | postfix   | 3 2 1 + +     |
      | borderfix | (+ 1 2 3)     |
      - infix is especially good for associative binary function
      - prefix and postfix are not ambiguous without bracket
      - borderfix can be used for functions
        that can apply to different numbers of arguments
      our choice is between prefix and postfix
      because for simplicity we have the following two features
      - the arity of all functions must be fixed
      - we want our expressions to be not ambiguous without bracket
      then, how do we decide to use postfix instead of prefix ?
      seemingly, prefix and postfix are symmetric
      while we still can distinguish them
      because we write in special order (from left to right in most western language)
      in postfix notation suppose we have written
      1 2 +
      and we want to add 3 to the result of 1 2 +
      we simply write
      1 2 + 3 +
      while in prefix notation suppose we have written
      @@html: + 1 2 @@
      and we want to add 3 to the result of + 1 2
      we have to insert + 3 in front of + 1 2 and write
      @@html: + 3 + 1 2 @@
      I summarize this difference by say
      postfix notation respect the special order of a linear writing system
      the above conclude my rationale

*** remark on the use of stack in implementation

    - first few versions is implemented as a stack-based language
      only later, changed to term-rewriting-system
      to make type inference easier

    - for basic information about stack-based language
      please see forth (the language)

    - for enlightening view of stack
      please see joy (the language)

*** rationale of composition over application

    - to optimize system for composition
      is to denote composition by concatenation of term

    - when optimize syntax for composition instead of application
      - we get better algebra-like structure
        because function composition is associative
        while function application is not
      - we lost good syntax for currying
        because currying is designed as a convention
        of the syntax of function application

*** remark on deduction and inference

    - one might ask, what is a deduction or a inference ?
      my answer is a deduction or a inference
      is a way to express a change of theorem
      "a change" means "one step of change"

    - let us generalize it a little bit
      and to discuss "a change of thing" and "language to record changes"
      you will find these two concepts are very common
      and they also are named differently in different places
      | thing   | a change of thing     | language to record changes |
      |---------+-----------------------+----------------------------|
      | theorem | deduction             | proof                      |
      | food    |                       | cookbook                   |
      | data    |                       | algorithm                  |
      | number  | elementary arithmetic |                            |
      (seems to me like a market for language designer)

*** >< remark on algebraic structure

    - the richness of algebraic structure

*** ><

***** concatenation, composition and cut

      - first syntax operation is concatenation
        concatenation of two names corresponds to

      - in the following example
        "*" can be readed as "define-hypothesis".
        #+begin_src scheme
        (* wanderer/poe (-> poe is-wanderer))
        (* way-worn (:x is-wanderer -> :x is-weary))

        (~ weary/poe (-> poe is-weary)
           (-> wanderer/poe way-worn))
        #+end_src

      - when view them as functions and types
        it is really intuitive to see
        with two functions "wanderer/poe" and "way-worn"
        how we can compose a function of type (-> poe is-weary)

***** other deductive rules of natural deduction

      - the following seems like conj-intro and conj-elim in natural deduction
        we can simply use stack processing function to express them
        - the types of stack processing functions
          should remind you of the so called structural rules of sequent calculus
        - linear logic and other substructural logics can be investigated under this framework
        #+begin_src scheme
        ;; conj-intro
        (* p1 (-> a))
        (* p2 (-> b))
        (~ p3 (-> a b)
           (-> p1 p2))

        (* drop (:t ->)
           (:d ->))
        (~ swap (:t1 :t2 -> :t2 :t1)
           (:d1 :d2 -> :d2 :d1))

        ;; conj-elim
        (* p3 (-> a b))
        (~ p1 (-> a)
           (-> p3 drop))
        (~ p2 (-> b)
           (-> p3 swap drop))
        #+end_src

***** the meaning of proof

      - we have the advantage to observe
        the concrete meaning of "proof" within our concrete model

      - concretely, how proof (type) is checked by the language ?
        I have the following summarization

        | arrow list in function body |                            |
        |-----------------------------+----------------------------|
        | for each arrow              | type-check                 |
        | for all antecedents         | cover-check                |
        | for each succedent          | structural-recursion-check |

      - to type-check one arrow, is to
        - unify the antecedent of type-arrow
          with the type of the antecedent of arrow
        - during which, variables will be bound to data or other variables
        - under these bindings
          try to cover the succedent of type-arrow
          by the type of the succedent of arrow

      - let us follow a check step by step
        #+begin_src scheme
        (+ natural (-> type)
           zero (-> natural)
           succ (natural -> natural))

        (+ list (type -> type)
           null (-> :t list)
           cons (:t list :t -> :t list))

        (~ map (:t1 list (:t1 -> :t2) -> :t2 list)
           (null :f -> null)
           (:l :e cons :f -> :l :f map :e :f apply cons))

        (+ has-length (:t list natural -> type)
           null/has-length (-> null zero has-length)
           cons/has-length (:l :n has-length -> :l :a cons :n succ has-length))

        (~ map/has-length (:l :n has-length -> :l :f map :n has-length)
           (null/has-length -> null/has-length)
           (:h cons/has-length -> :h map/has-length cons/has-length))

        ;; take the type check of the second arrow of map/has-length for example

        ;; unify the antecedent of type-arrow :
        (:l :n has-length)

        ;; with the type of antecedent of the second arrow :
        type of (:h cons/has-length)
        ==
        (:l:0 :a:0 cons :n:0 succ has-length)

        ;; bindings :
        ((:h : :l:0 :n:0 has-length)
         (:l = :l:0 :a:0 cons)
         (:n = :n:0 succ))

        ;; the type of the succedent of the second arrow :
        type of (:h map/has-length cons/has-length)
        == ;; under bindings
        (:l:0
         :n:0 has-length
         (type/apply map/has-length)
         (type/apply cons/has-length))
        ==
        (:l:0 :f:1 map
         :n:0 has-length
         (type/apply cons/has-length))
        ==
        (:l:0 :f:1 map :a:2 cons
         :n:0 succ has-length)

        ;; cover the succedent of type-arrow :
        (:l :f map :n has-length)
        == ;; under bindings
        (:l:0 :a:0 cons :f map
         :n:0 succ has-length)
        == ;; rewrite map
        (:l:0 :f map :a:0 :f apply cons
         :n:0 succ has-length)

        ;; cover :
        ((:f:1 = :f)
         (:a:2 = :a:0 :f apply))
        #+end_src

      - to summarize the meaning of "proof" within our concrete model
        - we can express theorems about
          - recursively defined data
          - recursively defined function
        - we can do proof by
          - cut -- function composition
          - exhaustion -- cover-check
          - structural induction --
            where first we proof some basic steps
            and by unification we get next-theorem
            (just as the next-number in natural-induction)
            a function recursive call is a use of the induction hypothesis
            aimming to prove the next-theorem

***** the meaning of proof, again

      - if we define natural number as the following
        then we can proof natural-induction
        #+begin_src scheme
        (+ natural (-> type)
           zero (-> natural)
           succ (natural -> natural))

        (~ natural-induction ((:p : (natural -> type))
                              zero :p apply
                              ((:k : natural) :k :p apply -> :k succ :p apply)
                              (:x : natural) -> :x :p apply)
           (:q :q/z :q/s zero -> :q/z)
           (:q :q/z :q/s :n succ ->
               :n
               :q :q/z :q/s :n natural-induction
               :q/s apply))

        ;; take the type check of the second arrow for example

        ;; unify the antecedent of type-arrow :
        ((:p : (natural -> type))
         zero :p apply
         ((:k : natural) :k :p apply -> :k succ :p apply)
         (:x : natural))

        ;; with the type of antecedent of the second arrow :
        type of (:q :q/z :q/s :n succ)

        ;; bindings :
        ((:p = :q)
         (:q : (natural -> type))
         (:q/z : zero :p apply)
         (:q/s : ((:k : natural) :k :p apply -> :k succ :p apply))
         (:x = :n)
         (:n : natural))

        ;; the type of the succedent of the second arrow :
        type of
        (:n
         :q :q/z :q/s :n natural-induction
         :q/s apply)
        == ;; under bindings
        ((:n : natural)
         (:q : (natural -> type))
         (:q/z : zero :q apply)
         (:q/s : ((:k : natural) :k :q apply -> :k succ :q apply))
         (:n : natural)
         natural-induction
         :q/s type/apply)
        ==
        ((:n : natural)
         :n :q apply
         :q/s type/apply)
        ==
        ((:n succ :q apply))

        ;; cover the succedent of type-arrow :
        (:x :p apply)
        == ;; under bindings
        ((:n succ :q apply))
        #+end_src

***** the use of "or"

      - when "or" is used
        we just need to cover all the cases
        #+begin_src scheme
        (~ length (:t list -> natural)
           (null -> zero)
           (:l :e cons -> :l length succ))

        (~ length ((natural or :t list) -> natural)
           (null -> zero)
           (:l :e cons -> :l length succ)
           (zero -> zero)
           (:n succ -> :n succ))

        (~ length ((natural or :t list) -> natural)
           (null -> zero)
           (:l :e cons -> :l length succ)
           (:n -> :n))
        #+end_src

      - type definition is like named "or"
        #+begin_src scheme
        (+ nali (-> type)
           na (natural -> nali)
           li (:t list -> nali))

        (~ nali/length (nali -> natural)
           (:l li -> :l length)
           (:n na -> :n))
        #+end_src

      - type definition is like named "or" of "and"s
        #+begin_src scheme
        (+ nanalili (-> type)
           nana (natural natural -> nanalili)
           lili (:t1 list :t2 list -> nanalili))

        (~ nanalili/length (nanalili -> natural)
           (:l1 li :l2 li -> :l1 length :l2 length add)
           (:n1 na :n2 na -> :n1 :n2 add))
        #+end_src

      - thus
        | function body                | deduction               |
        |------------------------------+-------------------------|
        | branching by a list of arrow | disj-elim or exist-elim |
        | binding by unification       | conj-elim               |
